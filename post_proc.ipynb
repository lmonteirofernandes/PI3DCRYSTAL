{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import matplotlib.pyplot as plt\n",
    "import psutil\n",
    "import time\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import csv\n",
    "import gc\n",
    "import itertools\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from mytools import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enabling garbage collector to save RAM\n",
    "gc.enable()\n",
    "\n",
    "## User configuration\n",
    "device = 'cpu'\n",
    "dataset_path = \"./data/\"\n",
    "input_name = \"quat_10000_32^3.npy\"\n",
    "gt_name = \"sigma_10000_32^3.npy\"\n",
    "model_path=\"./trained_models/\"\n",
    "model_name = \"bestmodel_selfsup_extension_xx_inner_depth_150_n_resblocks_4.pt\"\n",
    "outfolder='./post_proc_results/'\n",
    "n_train_val_samples = 6000 ## ALREADY USED FOR TRAINING AND VALIDATION\n",
    "n_test_samples = 1000 ## UNTOUCHED TEST DATA\n",
    "plot_dat_file_crops = True\n",
    "plot_crop = 0\n",
    "crop_positions = [0, 11, 21]\n",
    "\n",
    "## Creating analysis output folder\n",
    "os.system(\"mkdir -p \" + outfolder)\n",
    "\n",
    "## Loading datasets\n",
    "quat_dataset = np.load(dataset_path + input_name)\n",
    "sigma_fft_dataset = np.load(dataset_path + gt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separating the dataset into separate tensors\n",
    "quat_test = (\n",
    "    torch.from_numpy(quat_dataset[n_train_val_samples : n_train_val_samples + n_test_samples])\n",
    "    .to(gettensorprecision(precision))\n",
    "    .to(device)\n",
    ")\n",
    "sigma_fft_test = (\n",
    "    torch.from_numpy(\n",
    "        sigma_fft_dataset[n_train_val_samples : n_train_val_samples + n_test_samples]\n",
    "    )\n",
    "    .to(gettensorprecision(precision))\n",
    "    .to(device)\n",
    ")\n",
    "\n",
    "## Manually freeing some RAM\n",
    "del quat_dataset\n",
    "del sigma_fft_dataset\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading model in evaluation mode (we don't need to calculate gradients)\n",
    "trained_model = torch.load(model_path + model_name, map_location=torch.device(device))\n",
    "trained_model = trained_model.module.to(device)\n",
    "trained_model.eval()\n",
    "\n",
    "## Initializing arrays\n",
    "concat_fft_test = np.array([])\n",
    "concat_nn_test = np.array([])\n",
    "concat_vm_fft_test = np.array([])\n",
    "concat_vm_nn_test = np.array([])\n",
    "concat_grain_avg_gt = np.array([])\n",
    "concat_grain_avg_pred = np.array([])\n",
    "concat_grain_avg_gt_vm = np.array([])\n",
    "concat_grain_avg_pred_vm = np.array([])\n",
    "concat_grainsizes = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting clock\n",
    "t0 = time.time()\n",
    "\n",
    "## Analysis main loop\n",
    "for sample in range(n_test_samples):\n",
    "\n",
    "    concat_fft_test = np.concatenate(\n",
    "        (concat_fft_test, sigma_fft_test[sample, 0, :, :, :].cpu().detach().numpy().flatten())\n",
    "    )\n",
    "\n",
    "    concat_vm_fft_test = np.concatenate(\n",
    "        (concat_vm_fft_test, vm_vector(sigma_fft_test[sample].cpu()).flatten())\n",
    "    )\n",
    "\n",
    "    ## FOR MEASURING RAM AND TIME\n",
    "    # with torch.no_grad():\n",
    "    #     with profile(activities=[ProfilerActivity.CPU],profile_memory=True, record_shapes=True) as prof:\n",
    "    #         sig_nn_test  = trained_model(quat_test[sample:sample+1])\n",
    "    # print('self_cpu_memory_usage \\n')\n",
    "    # print(prof.key_averages().table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "    # print('cpu_memory_usage \\n')\n",
    "    # print(prof.key_averages().table(sort_by=\"cpu_memory_usage\", row_limit=10))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sig_nn_test = trained_model(quat_test[sample : sample + 1])\n",
    "\n",
    "    sig_nn_vm = vm_matrix(sig_nn_test.cpu())\n",
    "\n",
    "    sig_fft_vm = vm_vector(sigma_fft_test[sample].cpu())\n",
    "\n",
    "    concat_vm_nn_test = np.concatenate(\n",
    "        (concat_vm_nn_test, vm_matrix(sig_nn_test.cpu()).flatten())\n",
    "    )\n",
    "\n",
    "    concat_nn_test = np.concatenate(\n",
    "        (concat_nn_test, sig_nn_test[0, 0, 0, :, :, :].cpu().detach().numpy().flatten())\n",
    "    )\n",
    "\n",
    "    grain_avg_gt_sample, grain_avg_pred_sample, grainsizes_sample = (\n",
    "        performance_scatterplot(\n",
    "            quat_test[sample : sample + 1].to(\"cpu\"),\n",
    "            sigma_fft_test[sample : sample + 1, 0:1, :, :, :].to(\"cpu\"),\n",
    "            sig_nn_test[0:1, 0:1, 0, :, :, :].cpu(),\n",
    "            outfolder,\n",
    "            \"sigxx_\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    grain_avg_gt_sample_vm, grain_avg_pred_sample_vm, grainsizes_sample_vm = (\n",
    "        performance_scatterplot(\n",
    "            quat_test[sample : sample + 1].cpu(),\n",
    "            torch.Tensor(np.expand_dims(np.expand_dims(sig_fft_vm, axis=0), axis=0)).cpu(),\n",
    "            torch.Tensor(np.expand_dims(np.expand_dims(sig_nn_vm, axis=0), axis=0)).cpu(),\n",
    "            outfolder,\n",
    "            \"sig_eq_\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    concat_grain_avg_gt = np.concatenate((concat_grain_avg_gt, grain_avg_gt_sample))\n",
    "    concat_grain_avg_pred = np.concatenate(\n",
    "        (concat_grain_avg_pred, grain_avg_pred_sample)\n",
    "    )\n",
    "\n",
    "    concat_grain_avg_gt_vm = np.concatenate(\n",
    "        (concat_grain_avg_gt_vm, grain_avg_gt_sample_vm)\n",
    "    )\n",
    "    concat_grain_avg_pred_vm = np.concatenate(\n",
    "        (concat_grain_avg_pred_vm, grain_avg_pred_sample_vm)\n",
    "    )\n",
    "\n",
    "    concat_grainsizes = np.concatenate((concat_grainsizes, grainsizes_sample))\n",
    "\n",
    "    if plot_dat_file_crops == True and sample == plot_crop:\n",
    "        data_fft = sigma_fft_test[plot_crop, 0, :, :, :].cpu().detach().numpy()\n",
    "        data_nn = sig_nn_test[0, 0, 0, :, :, :].cpu().detach().numpy()\n",
    "        data_fft_vm = sig_fft_vm[:, :, :].cpu().detach().numpy()\n",
    "        data_nn_vm = np.squeeze(sig_nn_vm[:, :, :].cpu().detach().numpy())\n",
    "        data_error_abs = abs(data_fft - data_nn)\n",
    "        data_error_rel = data_error_abs / data_fft\n",
    "        data_error_abs_vm = abs(data_fft_vm - data_nn_vm)\n",
    "        data_error_rel_vm = data_error_abs_vm / data_fft_vm\n",
    "        n = data_nn.shape[0]\n",
    "\n",
    "        for x in crop_positions:\n",
    "            f = open(outfolder + \"sig_nn_xx_position_\" + str(x) + \".dat\", \"w\")\n",
    "            g = open(outfolder + \"sig_fft_xx_position_\" + str(x) + \".dat\", \"w\")\n",
    "            a = open(outfolder + \"err_abs_sig_xx_position_\" + str(x) + \".dat\", \"w\")\n",
    "            r = open(outfolder + \"err_rel_sig_xx_position_\" + str(x) + \".dat\", \"w\")\n",
    "            ff = open(outfolder + \"sig_nn_vm_position_\" + str(x) + \".dat\", \"w\")\n",
    "            gg = open(outfolder + \"sig_fft_vm_position_\" + str(x) + \".dat\", \"w\")\n",
    "            aa = open(outfolder + \"err_abs_sig_vm_position_\" + str(x) + \".dat\", \"w\")\n",
    "            rr = open(outfolder + \"err_rel_sig_vm_position_\" + str(x) + \".dat\", \"w\")\n",
    "\n",
    "            # f.write('y,z,data \\n')\n",
    "            for z in range(n):\n",
    "                for y in range(n):\n",
    "                    # f.write(str(y)+' '+str(z)+' '+str(data_nn[x,y,z])+'\\n')\n",
    "                    # g.write(str(y)+' '+str(z)+' '+str(data_fft[x,y,z])+'\\n')\n",
    "                    f.write(str(y) + \" \" + str(z) + \" \" + str(data_nn[x, y, z]) + \"\\n\")\n",
    "                    g.write(str(y) + \" \" + str(z) + \" \" + str(data_fft[x, y, z]) + \"\\n\")\n",
    "                    a.write(\n",
    "                        str(y)\n",
    "                        + \" \"\n",
    "                        + str(z)\n",
    "                        + \" \"\n",
    "                        + str(data_error_abs[x, y, z])\n",
    "                        + \"\\n\"\n",
    "                    )\n",
    "                    r.write(\n",
    "                        str(y)\n",
    "                        + \" \"\n",
    "                        + str(z)\n",
    "                        + \" \"\n",
    "                        + str(100 * data_error_rel[x, y, z])\n",
    "                        + \"\\n\"\n",
    "                    )\n",
    "                    ff.write(\n",
    "                        str(y) + \" \" + str(z) + \" \" + str(data_nn_vm[x, y, z]) + \"\\n\"\n",
    "                    )\n",
    "                    gg.write(\n",
    "                        str(y) + \" \" + str(z) + \" \" + str(data_fft_vm[x, y, z]) + \"\\n\"\n",
    "                    )\n",
    "                    aa.write(\n",
    "                        str(y)\n",
    "                        + \" \"\n",
    "                        + str(z)\n",
    "                        + \" \"\n",
    "                        + str(data_error_abs_vm[x, y, z])\n",
    "                        + \"\\n\"\n",
    "                    )\n",
    "                    rr.write(\n",
    "                        str(y)\n",
    "                        + \" \"\n",
    "                        + str(z)\n",
    "                        + \" \"\n",
    "                        + str(100 * data_error_rel_vm[x, y, z])\n",
    "                        + \"\\n\"\n",
    "                    )\n",
    "                f.write(\"\\n\")\n",
    "                g.write(\"\\n\")\n",
    "                a.write(\"\\n\")\n",
    "                r.write(\"\\n\")\n",
    "                ff.write(\"\\n\")\n",
    "                gg.write(\"\\n\")\n",
    "                aa.write(\"\\n\")\n",
    "                rr.write(\"\\n\")\n",
    "            f.close()\n",
    "            g.close()\n",
    "            a.close()\n",
    "            r.close()\n",
    "            ff.close()\n",
    "            gg.close()\n",
    "            aa.close()\n",
    "            rr.close()\n",
    "\n",
    "## Stop clock and save training time\n",
    "t1 = time.time()\n",
    "total_time = t1 - t0\n",
    "f = open(outfolder + \"inference_time.txt\", \"w\")\n",
    "f.write(\n",
    "    \"The inference lasted  \"\n",
    "    + convert_time(total_time)\n",
    "    + \" for \"\n",
    "    + str(n_test_samples)\n",
    "    + \" samples.\"\n",
    ")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CORRELATION DIAGRAM sigma_xx (voxelwise)\n",
    "plt.figure()\n",
    "plt.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "plt.scatter(concat_fft_test, concat_nn_test, alpha=0.05)\n",
    "plt.plot(\n",
    "    concat_fft_test,\n",
    "    concat_fft_test,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Identity line\",\n",
    ")\n",
    "plt.title(\"Voxelwise values\")\n",
    "plt.xlabel(\"FFT ground truth (MPa)\")\n",
    "plt.ylabel(\"NN prediction for sigma_xx (MPa)\")\n",
    "\n",
    "\n",
    "## CORRELATION DIAGRAM sigma_xx (grain avgs)\n",
    "plt.figure()\n",
    "plt.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "plt.scatter(concat_grain_avg_gt, concat_grain_avg_pred, alpha=0.2)\n",
    "plt.plot(\n",
    "    concat_grain_avg_gt,\n",
    "    concat_grain_avg_gt,\n",
    "    color=\"red\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=2,\n",
    "    label=\"Identity line\",\n",
    ")\n",
    "plt.legend()\n",
    "plt.axis(\"equal\")\n",
    "plt.title(\"Grainwise averages\")\n",
    "plt.xlabel(\"FFT ground truth (MPa)\")\n",
    "plt.ylabel(\"NN prediction for sigma_xx (MPa)\")\n",
    "\n",
    "## CORRELATION DIAGRAM sigma_eq (voxelwise)\n",
    "sig_fft_vm_vector = sig_fft_vm.flatten()\n",
    "sig_nn_vm_vector = sig_nn_vm.flatten()\n",
    "plt.figure()\n",
    "plt.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "plt.scatter(sig_fft_vm_vector, sig_nn_vm_vector, alpha=0.05)\n",
    "plt.plot(\n",
    "    sig_fft_vm_vector,\n",
    "    sig_fft_vm_vector,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Identity line\",\n",
    ")\n",
    "plt.title(\"Voxelwise values\")\n",
    "plt.xlabel(\"FFT ground truth (MPa)\")\n",
    "plt.ylabel(\"NN prediction for sigma_eq (MPa)\")\n",
    "\n",
    "## CORRELATION DIAGRAM sigma_eq (grain avgs)\n",
    "plt.figure()\n",
    "plt.ticklabel_format(axis=\"both\", style=\"sci\", scilimits=(0, 0))\n",
    "plt.scatter(concat_grain_avg_gt_vm, concat_grain_avg_pred_vm, alpha=0.2)\n",
    "plt.plot(\n",
    "    concat_grain_avg_gt_vm,\n",
    "    concat_grain_avg_gt_vm,\n",
    "    color=\"red\",\n",
    "    linestyle=\"--\",\n",
    "    linewidth=2,\n",
    "    label=\"Identity line\",\n",
    ")\n",
    "plt.title(\"Grainwise averages\")\n",
    "plt.xlabel(\"FFT ground truth (MPa)\")\n",
    "plt.ylabel(\"NN prediction for sigma_eq (MPa)\")\n",
    "\n",
    "\n",
    "## RELATIVE ERROR CDFs\n",
    "concat_rel_err = abs(concat_fft_test - concat_nn_test) / concat_fft_test\n",
    "concat_rel_err_vm = abs(concat_vm_fft_test - concat_vm_nn_test) / concat_vm_fft_test\n",
    "avg_rel_err = concat_rel_err.mean()\n",
    "avg_rel_err_vm = concat_rel_err_vm.mean()\n",
    "\n",
    "f = open(outfolder + \"avg_relative_error_\" + str(n_test_samples) + \"_samples.txt\", \"w\")\n",
    "f.write(\"The average relative error is  \" + str(avg_rel_err))\n",
    "f.close()\n",
    "\n",
    "f = open(outfolder + \"avg_relative_error_vm\" + str(n_test_samples) + \"_samples.txt\", \"w\")\n",
    "f.write(\"The average relative error for Von Mises stress is  \" + str(avg_rel_err_vm))\n",
    "f.close()\n",
    "\n",
    "np.savetxt(\n",
    "    outfolder + \"fft_flat_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_fft_test,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"fft_flat_vm_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_vm_fft_test,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"nn_flat_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_nn_test,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"nn_flat_vm_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_vm_nn_test,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"grain_avg_gt_flat_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_grain_avg_gt,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"grain_avg_pred_flat_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_grain_avg_pred,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"grain_avg_gt_flat_vm_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_grain_avg_gt_vm,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"grain_avg_pred_flat_vm_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_grain_avg_pred_vm,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"grainsizes_flat_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_grainsizes,\n",
    "    fmt=\"%d\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"rel_err_flat_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_rel_err,\n",
    "    fmt=\"%.5f\",\n",
    ")\n",
    "np.savetxt(\n",
    "    outfolder + \"rel_err_flat_vm_\" + str(n_test_samples) + \"_samples.dat\",\n",
    "    concat_rel_err_vm,\n",
    "    fmt=\"%.5f\",\n",
    ")\n",
    "\n",
    "\n",
    "err_xx = error_data(\"rel_err_flat_\" + str(n_test_samples) + \"_samples.dat\", outfolder)\n",
    "err_vm = error_data(\"rel_err_flat_vm_\" + str(n_test_samples) + \"_samples.dat\", outfolder)\n",
    "\n",
    "err_xx.load()\n",
    "err_vm.load()\n",
    "\n",
    "err_xx.pdf()\n",
    "err_vm.pdf()\n",
    "\n",
    "err_xx.cdf()\n",
    "err_vm.cdf()\n",
    "\n",
    "np.savetxt(outfolder+\"data_err_xx.dat\", err_xx.data, fmt=\"%f\")\n",
    "np.savetxt(outfolder+\"x_err_xx.dat\", err_xx.x, fmt=\"%f\")\n",
    "np.savetxt(outfolder+\"pdf_err_xx.dat\", err_xx.pdf, fmt=\"%f\")\n",
    "np.savetxt(outfolder+\"cdf_err_xx.dat\", err_xx.cdf, fmt=\"%f\")\n",
    "\n",
    "np.savetxt(outfolder+\"data_err_vm.dat\", err_vm.data, fmt=\"%f\")\n",
    "np.savetxt(outfolder+\"x_err_vm.dat\", err_vm.x, fmt=\"%f\")\n",
    "np.savetxt(outfolder+\"pdf_err_vm.dat\", err_vm.pdf, fmt=\"%f\")\n",
    "np.savetxt(outfolder+\"cdf_err_vm.dat\", err_vm.cdf, fmt=\"%f\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
